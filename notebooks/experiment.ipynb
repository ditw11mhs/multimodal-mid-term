{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e64285-fe77-4f70-b640-7838663b0ea5",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a0a93-543a-4cc6-9e38-f0507264a9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom as pdc\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125400b-a4a4-49ba-b18e-d5ff6f5e8e4a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a33be7-48e3-4c17-8d7f-68de3948e40c",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe25946-f2c9-4270-b39f-9234e8d65a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_patient_path_pair(\n",
    "    project_root_path: pathlib.Path, patient_list: List[int]\n",
    ") -> List[Tuple[pathlib.Path, pathlib.Path, pathlib.Path]]:\n",
    "    \"\"\"Create a list of tuples that contain the InPhase, OutPhase, and ground truth PNG file paths for each patient.\n",
    "\n",
    "    Args:\n",
    "        project_root_path: The path to the root directory of the project.\n",
    "        patient_list: A list of patient IDs.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples where each tuple contains the InPhase, OutPhase, and ground truth PNG file paths for a patient.\n",
    "    \"\"\"\n",
    "    patient_path_pair = []\n",
    "    for idx in tqdm(patient_list, desc=\"Creating Path Pairing\"):\n",
    "        mri_tdual_in_dcm_path = [\n",
    "            path.as_posix()\n",
    "            for path in sorted(\n",
    "                list(project_root_path.rglob(f\"MR/{idx}/T1DUAL/**/InPhase/*.dcm\"))\n",
    "            )\n",
    "        ]\n",
    "        mri_tdual_out_dcm_path = [\n",
    "            path.as_posix()\n",
    "            for path in sorted(\n",
    "                list(project_root_path.rglob(f\"MR/{idx}/T1DUAL/**/OutPhase/*.dcm\"))\n",
    "            )\n",
    "        ]\n",
    "        mri_tdual_ground_truth_path = [\n",
    "            path.as_posix()\n",
    "            for path in sorted(\n",
    "                list(project_root_path.rglob(f\"MR/{idx}/**/T1DUAL/Ground/*.png\"))\n",
    "            )\n",
    "        ]\n",
    "        for pair in zip(\n",
    "            mri_tdual_in_dcm_path, mri_tdual_out_dcm_path, mri_tdual_ground_truth_path\n",
    "        ):\n",
    "            patient_path_pair.append(pair)\n",
    "    return patient_path_pair\n",
    "\n",
    "\n",
    "def get_train_val_test_split(split: str, patient_list: List[int]) -> dict:\n",
    "    \"\"\"Split the list of patients into train, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        split: A string with three numbers separated by commas that represent the percentage of patients to include in the train, validation, and test sets, respectively.\n",
    "        patient_list: A list of patient IDs.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with keys \"train\", \"val\", and \"test\" that each have a corresponding list of patient IDs.\n",
    "    \"\"\"\n",
    "    random_patient_list = patient_list\n",
    "    random.shuffle(random_patient_list)\n",
    "\n",
    "    n = len(patient_list)\n",
    "\n",
    "    n_train = int(n * (int(split[0]) / 10))\n",
    "    n_val = int(n * (int(split[1]) / 10))\n",
    "    n_test = int(n * (int(split[2]) / 10))\n",
    "\n",
    "    train = random_patient_list[:n_train]\n",
    "    val = random_patient_list[n_train : n - n_test]\n",
    "    test = random_patient_list[n_train + n_val :]\n",
    "    return {\"train\": train, \"val\": val, \"test\": test}\n",
    "\n",
    "\n",
    "def get_dcm_img(dcm_path):\n",
    "    \"\"\"Load DICOM file and return pixel data .\n",
    "\n",
    "    Args:\n",
    "        dcm_path: The path to the DICOM file.\n",
    "\n",
    "    Returns:\n",
    "        The DICOM file with img.\n",
    "    \"\"\"\n",
    "    image_bytes = tf.io.read_file(dcm_path)\n",
    "    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_dcm(dcm_path):\n",
    "    img = get_dcm_img(dcm_path)\n",
    "    # Normalize uint16 to [0,1]\n",
    "    img_norm = img / tf.cast(65535, tf.uint16)\n",
    "    return img_norm\n",
    "\n",
    "\n",
    "def preprocess_ground(png_path):\n",
    "    png = tf.io.read_file(png_path)\n",
    "    png_array = tf.io.decode_png(png, channels=1)\n",
    "    png_mask = tf.cast(tf.equal(png_array, 63), tf.uint8)\n",
    "    return png_mask\n",
    "\n",
    "\n",
    "def parsed_path_to_dataset(features):\n",
    "    in_img = preprocess_dcm(features[0])\n",
    "    out_img = preprocess_dcm(features[1])\n",
    "    ground_truth = preprocess_ground(features[2])\n",
    "    return (in_img, out_img), ground_truth\n",
    "\n",
    "\n",
    "def load_dicom_image(dicom_path):\n",
    "    \"\"\"\n",
    "    Load DICOM file from given path and decode it using TensorFlow I/O.\n",
    "\n",
    "    Args:\n",
    "        dicom_path (str): The path to the DICOM file.\n",
    "\n",
    "    Returns:\n",
    "        The decoded DICOM image.\n",
    "    \"\"\"\n",
    "    image_bytes = tf.io.read_file(dicom_path)\n",
    "    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n",
    "    return image\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the given image to the range [0, 1] by dividing it by the maximum value (2^16-1).\n",
    "\n",
    "    Args:\n",
    "        image (tf.Tensor): The image to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        The normalized image.\n",
    "    \"\"\"\n",
    "    max_value = tf.cast(65535, tf.uint16)\n",
    "    normalized_image = tf.divide(image, max_value)\n",
    "    return normalized_image\n",
    "\n",
    "\n",
    "def load_ground_truth_mask(png_path):\n",
    "    \"\"\"\n",
    "    Load the ground truth mask from the given PNG file path and convert it to binary mask.\n",
    "\n",
    "    Args:\n",
    "        png_path (str): The path to the PNG file.\n",
    "\n",
    "    Returns:\n",
    "        The binary mask of the ground truth.\n",
    "    \"\"\"\n",
    "    png = tf.io.read_file(png_path)\n",
    "    png_array = tf.io.decode_png(png, channels=1)\n",
    "    ground_truth_mask = tf.cast(tf.equal(png_array, 63), tf.uint8)\n",
    "    return ground_truth_mask\n",
    "\n",
    "\n",
    "def parse_path_to_dataset(path_list):\n",
    "    \"\"\"\n",
    "    Load and preprocess the DICOM image and the ground truth mask from the given path list.\n",
    "\n",
    "    Args:\n",
    "        path_list (list): A list of paths to DICOM and PNG files.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of the preprocessed in-phase and out-of-phase images and the ground truth mask.\n",
    "    \"\"\"\n",
    "    in_phase_image = load_dicom_image(path_list[0])\n",
    "    out_phase_image = load_dicom_image(path_list[1])\n",
    "    ground_truth_mask = load_ground_truth_mask(path_list[2])\n",
    "    in_phase_image_norm = normalize_image(in_phase_image)\n",
    "    out_phase_image_norm = normalize_image(out_phase_image)\n",
    "    return (in_phase_image_norm, out_phase_image_norm), ground_truth_mask\n",
    "\n",
    "\n",
    "def get_dataset(pair_path_list, batch_size):\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(pair_path_list).map(\n",
    "            parse_path_to_dataset, num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "        # .shuffle(batch_size * 10)\n",
    "        # .batch(batch_size)\n",
    "        # .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0730a07-b15f-49e5-8839-10d565e38ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project root path\n",
    "project_root_path = pathlib.Path.cwd().parent\n",
    "\n",
    "# Set a list of patient IDs\n",
    "patient_list = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    5,\n",
    "    8,\n",
    "    10,\n",
    "    13,\n",
    "    15,\n",
    "    19,\n",
    "    20,\n",
    "    21,\n",
    "    22,\n",
    "    31,\n",
    "    32,\n",
    "    33,\n",
    "    34,\n",
    "    36,\n",
    "    37,\n",
    "    38,\n",
    "    39,\n",
    "]\n",
    "\n",
    "# Get patient split\n",
    "patient_split = get_train_val_test_split(\"721\", patient_list)\n",
    "\n",
    "# Get train, test, and val split\n",
    "train_path_pair = get_patient_path_pair(project_root_path, patient_split[\"train\"])\n",
    "val_path_pair = get_patient_path_pair(project_root_path, patient_split[\"val\"])\n",
    "test_path_pair = get_patient_path_pair(project_root_path, patient_split[\"test\"])\n",
    "\n",
    "# Create Dataset\n",
    "batch_size = 10\n",
    "train_dataset = get_dataset(train_path_pair, batch_size)\n",
    "val_dataset = get_dataset(val_path_pair, batch_size)\n",
    "test_dataset = get_dataset(test_path_pair, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee4bad-90b0-454d-b119-caa5ed80f757",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0173f4-7927-4235-9119-24ba2207d9a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90861e2f-61e0-45be-9d7f-9cbb2e5319be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(\n",
    "    node_name: str,\n",
    "    n_filter: int,\n",
    "    batch_norm: bool,\n",
    "    strides: int,\n",
    "    kernel: int,\n",
    "):\n",
    "    def layer(input_tensor: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        A pointwise convolution block with added linearity or non-linearity (ReLU6).\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tf.Tensor): Input tensor to the layer.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Output tensor of the layer.\n",
    "        \"\"\"\n",
    "        x = layers.Conv2D(\n",
    "            n_filter,\n",
    "            kernel,\n",
    "            strides=strides,\n",
    "            padding=\"same\",\n",
    "            name=f\"{node_name}_conv_block\",\n",
    "        )(input_tensor)\n",
    "        if batch_norm:\n",
    "            x = layers.BatchNormalization(name=f\"{node_name}_conv_block_bnorm\")(x)\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def pointwise_block(\n",
    "    node_name: str,\n",
    "    n_filter: int,\n",
    "    batch_norm: bool,\n",
    "    linear: bool,\n",
    "    strides: int = 1,\n",
    "    kernel: int = 1,\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    Returns a pointwise convolutional layer with optional batch normalization and activation.\n",
    "\n",
    "    Args:\n",
    "        node_name (str): Name of the layer.\n",
    "        n_filter (int): Number of filters for the convolutional layer.\n",
    "        batch_norm (bool): Whether to apply batch normalization.\n",
    "        linear (bool): Whether to apply activation (relu6) after the convolutional layer.\n",
    "        strides (int, optional): Stride of the convolutional layer. Defaults to 1.\n",
    "        kernel (int, optional): Kernel size of the convolutional layer. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        callable: Function that returns the layer when called with an input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def layer(input_tensor: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        A pointwise convolution block with added linearity or non-linearity (ReLU6).\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tf.Tensor): Input tensor to the layer.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Output tensor of the layer.\n",
    "        \"\"\"\n",
    "        x = layers.Conv2D(\n",
    "            n_filter, kernel, strides=strides, padding=\"same\", name=f\"{node_name}_pwise\"\n",
    "        )(input_tensor)\n",
    "        if batch_norm:\n",
    "            x = layers.BatchNormalization(name=f\"{node_name}_pwise_bnorm\")(x)\n",
    "        if not linear:\n",
    "            x = layers.Activation(tf.nn.relu6, name=f\"{node_name}_pwise_relu6\")(x)\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def depthwise_block(\n",
    "    node_name: str, batch_norm: bool, strides: int = 1, kernel: int = 3\n",
    ") -> Callable:\n",
    "    \"\"\"Create a depthwise convolution block with relu6 activation.\n",
    "\n",
    "    Args:\n",
    "        node_name (str): Name of the block.\n",
    "        batch_norm (bool): Whether or not to apply batch normalization.\n",
    "        strides (int, optional): The strides of the convolution along the height and width. Defaults to 1.\n",
    "        kernel (int, optional): Integer, the size of the kernel to be used in depthwise convolution. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A callable object that applies the depthwise convolution block to the input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def layer(input_tensor: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Applies depthwise convolution block to input_tensor.\n",
    "\n",
    "        Args:\n",
    "            input_tensor (tf.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        x = layers.DepthwiseConv2D(\n",
    "            kernel, strides=strides, padding=\"same\", name=f\"{node_name}_dwise\"\n",
    "        )(input_tensor)\n",
    "        if batch_norm:\n",
    "            x = layers.BatchNormalization(name=f\"{node_name}_dwise_bnorm\")(x)\n",
    "        x = layers.Activation(tf.nn.relu6, name=f\"{node_name}_dwise_relu6\")(x)\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def inverted_residual_bottleneck_block(\n",
    "    node_name: str,\n",
    "    n_filter: int,\n",
    "    strides: int,\n",
    "    t_expansion: int,\n",
    "    batch_norm: bool,\n",
    "    residual: bool = False,\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    A bottleneck block containing expansion and compression using pointwise and depthwise convolutions\n",
    "    followed by optional residual connection.\n",
    "\n",
    "    Args:\n",
    "        node_name: A name for the block.\n",
    "        n_filter: Number of filters in the output tensor.\n",
    "        strides: Stride size of the depthwise convolution.\n",
    "        t_expansion: Expansion factor for the number of filters in the expansion layer.\n",
    "        batch_norm: Whether to apply batch normalization after each convolution.\n",
    "        residual: Whether to apply a residual connection to the output tensor.\n",
    "\n",
    "    Returns:\n",
    "        A callable that takes an input tensor and returns the output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def layer(input_tensor: tf.Tensor) -> tf.Tensor:\n",
    "        expanded_filter = keras.backend.int_shape(input_tensor)[-1] * t_expansion\n",
    "\n",
    "        # Expansion layer\n",
    "        x = pointwise_block(\n",
    "            node_name=node_name + \"_expand\",\n",
    "            n_filter=expanded_filter,\n",
    "            batch_norm=batch_norm,\n",
    "            linear=False,\n",
    "        )(input_tensor)\n",
    "\n",
    "        # Depthwise Layer\n",
    "        x = depthwise_block(\n",
    "            node_name=node_name + \"_depthwise\",\n",
    "            batch_norm=batch_norm,\n",
    "            strides=strides,\n",
    "            kernel=3,\n",
    "        )(x)\n",
    "\n",
    "        # Compression layer\n",
    "        x = pointwise_block(\n",
    "            node_name=node_name + \"_compress\",\n",
    "            n_filter=n_filter,\n",
    "            batch_norm=batch_norm,\n",
    "            strides=1,\n",
    "            kernel=1,\n",
    "            linear=True,\n",
    "        )(x)\n",
    "\n",
    "        if residual:\n",
    "            x = layers.Add(name=f\"{node_name}_add\")([x, input_tensor])\n",
    "\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def sequence_inv_res_bot_block(\n",
    "    node_name, n_filter, batch_norm, strides, t_expansion, n_iter\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    A layer containing a sequence of inverted\n",
    "    residual bottleneck block that is repeated\n",
    "    n_iter times\n",
    "\n",
    "    Args:\n",
    "        node_name (str):\n",
    "        n_filter (int):\n",
    "        batch_norm (bool):\n",
    "        strides (int):\n",
    "        t_expansion (int):\n",
    "        n_iter (int):\n",
    "\n",
    "    Returns:\n",
    "        Callable: A callable Keras layer that applies the sequence of inverted residual bottleneck blocks to an input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        x = inverted_residual_bottleneck_block(\n",
    "            node_name=f\"x_{node_name}_iter0\",\n",
    "            n_filter=n_filter,\n",
    "            batch_norm=batch_norm,\n",
    "            strides=strides,\n",
    "            t_expansion=t_expansion,\n",
    "            residual=False,\n",
    "        )(input_tensor)\n",
    "\n",
    "        for index in range(1, n_iter):\n",
    "            x = inverted_residual_bottleneck_block(\n",
    "                node_name=f\"x_{node_name}_iter{index}\",\n",
    "                n_filter=n_filter,\n",
    "                batch_norm=batch_norm,\n",
    "                strides=1,\n",
    "                t_expansion=t_expansion,\n",
    "                residual=True,\n",
    "            )(x)\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def upsample_block(\n",
    "    node_name, n_filter, batch_norm, n_kernel=2, mode=\"upsample\"\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    Upsample block containing different types of upsampling methods.\n",
    "\n",
    "    Args:\n",
    "        node_name (str): Name of the layer\n",
    "        n_filter (int): Number of filters in the convolution layer\n",
    "        batch_norm (bool): Whether to use batch normalization or not\n",
    "        n_kernel (int): Kernel size of the convolution layer\n",
    "        mode (str): Upsampling mode. Can be either \"upsample\" or \"transpose\".\n",
    "\n",
    "    Returns:\n",
    "        A Keras layer that performs upsampling.\n",
    "    \"\"\"\n",
    "    if mode == \"upsample\":\n",
    "\n",
    "        def layer(input_tensor):\n",
    "            x = layers.UpSampling2D(size=2, name=f\"x_{node_name}_upsample\")(\n",
    "                input_tensor\n",
    "            )\n",
    "            return x\n",
    "\n",
    "    elif mode == \"transpose\":\n",
    "\n",
    "        def layer(input_tensor):\n",
    "            x = layers.Conv2DTranspose(\n",
    "                filters=n_filter,\n",
    "                kernel_size=n_kernel,\n",
    "                strides=2,\n",
    "                name=f\"x_{node_name}_transpose\",\n",
    "                padding=\"same\",\n",
    "            )(input_tensor)\n",
    "\n",
    "            # Batch Norm\n",
    "            if batch_norm:\n",
    "                x = layers.BatchNormalization(name=f\"x_{node_name}_transpose_bn\")(x)\n",
    "\n",
    "            # Activation\n",
    "            x = layers.Activation(\"relu\", name=f\"x_{node_name}_transpose_activation\")(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode can only be either upsample or transpose\")\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460a583-119e-41db-9e5c-5bc6a546b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi input (multimodal) MobileNetV2\n",
    "\n",
    "input_in_phase = layers.Input(name=\"in_phase_input\", shape=(256, 256, 1))\n",
    "input_out_phase = layers.Input(name=\"out_phase_input\", shape=(256, 256, 1))\n",
    "\n",
    "x = layers.Concatenate()([input_in_phase, input_out_phase])\n",
    "x = conv_block(node_name=\"x_0\", n_filter=32, batch_norm=True, kernel=3, strides=2)(x)\n",
    "\n",
    "# Encoder\n",
    "\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_1\", n_filter=16, batch_norm=True, strides=1, t_expansion=1, n_iter=1\n",
    ")(x)\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_2\", n_filter=24, batch_norm=True, strides=2, t_expansion=6, n_iter=2\n",
    ")(x)\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_3\", n_filter=32, batch_norm=True, strides=2, t_expansion=6, n_iter=3\n",
    ")(x)\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_4\", n_filter=64, batch_norm=True, strides=2, t_expansion=6, n_iter=4\n",
    ")(x)\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_5\", n_filter=96, batch_norm=True, strides=1, t_expansion=6, n_iter=3\n",
    ")(x)\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_6\", n_filter=160, batch_norm=True, strides=2, t_expansion=6, n_iter=3\n",
    ")(x)\n",
    "x = sequence_inv_res_bot_block(\n",
    "    node_name=\"enc_7\", n_filter=320, batch_norm=True, strides=1, t_expansion=6, n_iter=1\n",
    ")(x)\n",
    "\n",
    "x = pointwise_block(\n",
    "    node_name=\"mid_8\",\n",
    "    n_filter=1280,\n",
    "    batch_norm=True,\n",
    "    linear=False,\n",
    ")(x)\n",
    "\n",
    "# Decoder\n",
    "x = upsample_block(\n",
    "    node_name=\"dec_9\", n_filter=320, batch_norm=True, n_kernel=2, mode=\"transpose\"\n",
    ")(x)\n",
    "\n",
    "x = upsample_block(\n",
    "    node_name=\"dec_10\", n_filter=160, batch_norm=True, n_kernel=2, mode=\"transpose\"\n",
    ")(x)\n",
    "\n",
    "x = upsample_block(\n",
    "    node_name=\"dec_11\", n_filter=96, batch_norm=True, n_kernel=2, mode=\"transpose\"\n",
    ")(x)\n",
    "\n",
    "x = upsample_block(\n",
    "    node_name=\"dec_12\", n_filter=64, batch_norm=True, n_kernel=2, mode=\"transpose\"\n",
    ")(x)\n",
    "\n",
    "x = upsample_block(\n",
    "    node_name=\"dec_13\", n_filter=32, batch_norm=True, n_kernel=2, mode=\"transpose\"\n",
    ")(x)\n",
    "\n",
    "x = layers.Conv2D(1, 3, strides=1, padding=\"same\", name=f\"output_pwise\")(x)\n",
    "\n",
    "x = layers.BatchNormalization(name=\"output_pwise_bnorm\")(x)\n",
    "x = layers.Activation(\"softmax\", name=f\"output_pwise_softmax\")(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    [input_in_phase, input_out_phase], x, name=\"multimodal_encoder_decoder_mobilenetV2\"\n",
    ")\n",
    "# plot_model(model, to_file=\"images/MobileNetv2.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59660442-3496-4bda-8401-922f6cde31f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e7e98-b8e3-46be-9a2c-83e35680d4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.binary_focal_crossentropy,\n",
    "    metrics=[tf.keras.metrics.binary_focal_crossentropy, \"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914657cd-b127-4f77-9450-6dad959411c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x=train_dataset, validation_data=val_dataset, epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aede210-25bc-4c94-9f7e-4acf55873c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e64285-fe77-4f70-b640-7838663b0ea5",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2a0a93-543a-4cc6-9e38-f0507264a9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 23:29:09.523657: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-06 23:29:09.576494: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-06 23:29:09.578767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 23:29:10.710401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import numpy as np\n",
    "import pydicom as pdc\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125400b-a4a4-49ba-b18e-d5ff6f5e8e4a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a33be7-48e3-4c17-8d7f-68de3948e40c",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe25946-f2c9-4270-b39f-9234e8d65a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_patient_path_pair(project_root_path: pathlib.Path, patient_list: List[int]) -> List[Tuple[pathlib.Path, pathlib.Path, pathlib.Path]]:\n",
    "    \"\"\"Create a list of tuples that contain the InPhase, OutPhase, and ground truth PNG file paths for each patient.\n",
    "\n",
    "    Args:\n",
    "        project_root_path: The path to the root directory of the project.\n",
    "        patient_list: A list of patient IDs.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples where each tuple contains the InPhase, OutPhase, and ground truth PNG file paths for a patient.\n",
    "    \"\"\"\n",
    "    patient_path_pair = []\n",
    "    for idx in tqdm(patient_list, desc=\"Creating Path Pairing\"):\n",
    "        mri_tdual_in_dcm_path = [path.as_posix() for path in sorted(list(project_root_path.rglob(f\"MR/{idx}/T1DUAL/**/InPhase/*.dcm\")))]\n",
    "        mri_tdual_out_dcm_path = [path.as_posix() for path in sorted(list(project_root_path.rglob(f\"MR/{idx}/T1DUAL/**/OutPhase/*.dcm\")))]\n",
    "        mri_tdual_ground_truth_path = [path.as_posix() for path in sorted(list(project_root_path.rglob(f\"MR/{idx}/**/T1DUAL/Ground/*.png\")))]\n",
    "        for pair in zip(mri_tdual_in_dcm_path,mri_tdual_out_dcm_path,mri_tdual_ground_truth_path):\n",
    "            patient_path_pair.append(pair)\n",
    "    return patient_path_pair\n",
    "\n",
    "def get_train_val_test_split(split: str, patient_list: List[int]) -> dict:\n",
    "    \"\"\"Split the list of patients into train, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        split: A string with three numbers separated by commas that represent the percentage of patients to include in the train, validation, and test sets, respectively.\n",
    "        patient_list: A list of patient IDs.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with keys \"train\", \"val\", and \"test\" that each have a corresponding list of patient IDs.\n",
    "    \"\"\"\n",
    "    random_patient_list = patient_list\n",
    "    random.shuffle(random_patient_list)\n",
    "    \n",
    "    n = len(patient_list)\n",
    "    \n",
    "    n_train = int(n*(int(split[0])/10))\n",
    "    n_val = int(n*(int(split[1])/10))\n",
    "    n_test = int(n*(int(split[2])/10))\n",
    "                \n",
    "    train = random_patient_list[:n_train]\n",
    "    val = random_patient_list[n_train:n-n_test]\n",
    "    test = random_patient_list[n_train+n_val:]\n",
    "    return {\"train\":train,\"val\":val,\"test\":test}\n",
    "\n",
    "def get_dcm_img(dcm_path):\n",
    "    \"\"\"Load DICOM file and return pixel data .\n",
    "\n",
    "    Args:\n",
    "        dcm_path: The path to the DICOM file.\n",
    "\n",
    "    Returns:\n",
    "        The DICOM file with img.\n",
    "    \"\"\"\n",
    "    image_bytes = tf.io.read_file(dcm_path)\n",
    "    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n",
    "    return image\n",
    "\n",
    "def preprocess_dcm(dcm_path):\n",
    "    img = get_dcm_img(dcm_path)\n",
    "    #Normalize uint16 to [0,1]\n",
    "    img_norm = img / tf.cast(65535,tf.uint16)\n",
    "    return img_norm\n",
    "\n",
    "def preprocess_ground(png_path):\n",
    "    png = tf.io.read_file(png_path)\n",
    "    png_array = tf.io.decode_png(png,channels=1)\n",
    "    png_mask = tf.cast(tf.equal(png_array, 63), tf.uint8)\n",
    "    return png_mask\n",
    "\n",
    "def parsed_path_to_dataset(features):\n",
    "    in_img = preprocess_dcm(features[0])\n",
    "    out_img = preprocess_dcm(features[1])\n",
    "    ground_truth = preprocess_ground(features[2])\n",
    "    return (in_img,out_img),ground_truth\n",
    "\n",
    "def load_dicom_image(dicom_path):\n",
    "    \"\"\"\n",
    "    Load DICOM file from given path and decode it using TensorFlow I/O.\n",
    "\n",
    "    Args:\n",
    "        dicom_path (str): The path to the DICOM file.\n",
    "\n",
    "    Returns:\n",
    "        The decoded DICOM image.\n",
    "    \"\"\"\n",
    "    image_bytes = tf.io.read_file(dicom_path)\n",
    "    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n",
    "    return image\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize the given image to the range [0, 1] by dividing it by the maximum value (2^16-1).\n",
    "\n",
    "    Args:\n",
    "        image (tf.Tensor): The image to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        The normalized image.\n",
    "    \"\"\"\n",
    "    max_value = tf.cast(65535, tf.uint16)\n",
    "    normalized_image = tf.divide(image, max_value)\n",
    "    return normalized_image\n",
    "\n",
    "\n",
    "def load_ground_truth_mask(png_path):\n",
    "    \"\"\"\n",
    "    Load the ground truth mask from the given PNG file path and convert it to binary mask.\n",
    "\n",
    "    Args:\n",
    "        png_path (str): The path to the PNG file.\n",
    "\n",
    "    Returns:\n",
    "        The binary mask of the ground truth.\n",
    "    \"\"\"\n",
    "    png = tf.io.read_file(png_path)\n",
    "    png_array = tf.io.decode_png(png, channels=1)\n",
    "    ground_truth_mask = tf.cast(tf.equal(png_array, 63), tf.uint8)\n",
    "    return ground_truth_mask\n",
    "\n",
    "\n",
    "def parse_path_to_dataset(path_list):\n",
    "    \"\"\"\n",
    "    Load and preprocess the DICOM image and the ground truth mask from the given path list.\n",
    "\n",
    "    Args:\n",
    "        path_list (list): A list of paths to DICOM and PNG files.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of the preprocessed in-phase and out-of-phase images and the ground truth mask.\n",
    "    \"\"\"\n",
    "    in_phase_image = load_dicom_image(path_list[0])\n",
    "    out_phase_image = load_dicom_image(path_list[1])\n",
    "    ground_truth_mask = load_ground_truth_mask(path_list[2])\n",
    "    in_phase_image_norm = normalize_image(in_phase_image)\n",
    "    out_phase_image_norm = normalize_image(out_phase_image)\n",
    "    return (in_phase_image_norm, out_phase_image_norm), ground_truth_mask\n",
    "\n",
    "def get_dataset(pair_path_list,batch_size):\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(pair_path_list)\n",
    "        .map(parse_path_to_dataset,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .shuffle(batch_size * 10)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0730a07-b15f-49e5-8839-10d565e38ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Path Pairing: 100%|█| 14/14 [00:00<00:\n",
      "Creating Path Pairing: 100%|█| 4/4 [00:00<00:00\n",
      "Creating Path Pairing: 100%|█| 2/2 [00:00<00:00\n"
     ]
    }
   ],
   "source": [
    "# Get the project root path\n",
    "project_root_path = pathlib.Path.cwd().parent\n",
    "\n",
    "# Set a list of patient IDs\n",
    "patient_list = [1, 2, 3, 5, 8, 10, 13, 15, 19, 20, 21, 22, 31, 32, 33, 34, 36, 37, 38, 39]\n",
    "\n",
    "# Get patient split\n",
    "patient_split = get_train_val_test_split(\"721\",patient_list)\n",
    "\n",
    "# Get train, test, and val split\n",
    "train_path_pair = get_patient_path_pair(project_root_path,patient_split[\"train\"])\n",
    "val_path_pair = get_patient_path_pair(project_root_path,patient_split[\"val\"])\n",
    "test_path_pair = get_patient_path_pair(project_root_path,patient_split[\"test\"])\n",
    "\n",
    "# Create Dataset\n",
    "batch_size=10\n",
    "train_dataset = get_dataset(train_path_pair,batch_size)\n",
    "val_dataset = get_dataset(val_path_pair,batch_size)\n",
    "test_dataset = get_dataset(test_path_pair,batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
